---
title: "Random variables and expected values"
date: "2021-02-19 12:27"
lang: en
featured: false
mathjax: true
---

# True/False becomes 1/0
If $Q$ is a yes-no question, we will use the notation $ã€šQã€›$ to represent this:

$$ã€šQã€›=\begin{cases}
1\quad\text{if }Q\text{ is true}\\
0\quad\text{if }Q\text{ is false}
\end{cases}$$

Then instead of writing
$$â„™(E)=\sum_{Ï‰ âˆˆ E}p(Ï‰)$$
we can write
$$â„™(E)=\sum_{Ï‰}p(Ï‰) ã€šÏ‰ âˆˆ Eã€›$$

## Examples
1. It is nicer to write the sum limits
    $$\sum_{x=1}^{10} x = \sum_x x ã€š 1â‰¤xâ‰¤10ã€›$$

2. It is nicer to change variables
    $$\sum_{x=-3}^{3} x^2 = \sum_x x^2 ã€š-3â‰¤xâ‰¤3ã€›= \sum_x (x-3)^2 ã€š0â‰¤xâ‰¤6ã€›$$


# Random variables
If we can calculate a number that depends on the outcome of an experiment, that number is called **random variable**

Formally, a random variable is any function $X:Î© â†’ â„$. For example, if we throw two dice, we can define $X(Ï‰)$ to be the sum of the spots on the outcome $Ï‰$

The probability that the spots total seven is the probability of the event $X(Ï‰) = 7$

To simplify, instead of $â„™(X(Ï‰) = 7)$ we write $â„™(X = 7)$

## Examples
+ Numbers in a dice
+ size of a plant
+ weight of an animal
+ temperature
+ age of a person

# Average, that is, mean value
What is the average age of people in Turkey? We have ğ‘› people, that we can identify with an index ğ‘– from 1 to ğ‘›. Let's represent the age of person ğ‘– with the symbol $x_i.$ Now we can represent all the population with a vector $ğ± = (x_1, â€¦, x_n).$ For now we will assume that we know all these $x_i$ values, and we will calculate some numbers with them.

Notice that we write the vector with a bold-face roman ğ±, and each one of the values with a subindex and italic font $x_i.$

The mean value if the vector $ğ± = (x_1, â€¦, x_n)$ is
$$\text{mean}(ğ±)=\bar ğ± = \frac{1}{n}\sum_i x_i$$

The (absolute) frequency, or count, of each value ğ‘¥ is
$$N(x)=\sum_i ã€šx_i=xã€›$$

The proportion, or relative frequency, of each value ğ‘¥ is
$$p(x)=\frac{N(x)}{n}$$

For a vector $ğ± = (x_1, â€¦, x_n)$ we have
$$\text{mean}(ğ±)=\sum_x x \frac{N(x)}{n}=\sum_x x\, p(x)$$

Now we notice that the proportion $p(x)$ is also the probability $â„™(X=x).$ We do not need to know ğ‘›. Sometimes it may not even be possible to know ğ‘›. Fortunately, we only need to know $â„™(X=x).$
<!-- find a new symbol for the free variable, instead of ğ‘¥. Maybe Ï‰, maybe ğ‘. -->

# Expected value - Mean value
For any random variable $X$ we define the **expected value** (also called **mean value**) of $X$ as the average of $X(Ï‰)$ over the population $Î©$
$$ğ”¼X=\sum_Ï‰ X(Ï‰)\, â„™(X(Ï‰))=\sum_Ï‰ X(Ï‰)\, p(Ï‰)$$
$$ğ”¼X=\sum_x x\, â„™(X=x)$$
Notice that $X$ is a random variable but $ğ”¼X$ is not.

Sometimes, for a given population and random variable, we call $Î¼=ğ”¼X$

## Expected value is linear
If $X$ and $Y$ are two random variables, and $Î±$ is a real number, then

+ $ğ”¼(X + Y)=ğ”¼X + ğ”¼Y$
+ $ğ”¼(Î±â‹…X)=Î±â‹…ğ”¼X$

So, if $Î±$ and $Î²$ are real numbers, then

+ $ğ”¼(Î±â‹…X +Î²â‹…Y)=Î±â‹…ğ”¼X +Î²â‹…ğ”¼Y$

## Example: expected value of coins
Let $X$ be a random variable corresponding to "success" or "failure", that we will represent by 1 and 0. The probability of success is $p$, and the probability of failure is $q.$

The expected value of $X$ is
$$ğ”¼(X) = \sum_{xâˆˆ\{0,1\}} xâ„™(X=x) = 1â‹…p + 0â‹…q = p$$

Now consider $n$ independent coins, all with the same probability of success, and we want to know how many of them are successful. Let
$$Y_n =\sum_{k=0}^n X_i.$$
Then
$$ğ”¼(Y_n) = ğ”¼\left(\sum_{k=1}^n X_i\right)=\sum_{k=1}^n ğ”¼(X_i)=\sum_{k=1}^n p = nâ‹…p$$



# Variance of the population
The **variance of the population** is defined with the same idea as the sample variance
$$ğ•X=ğ”¼(X-ğ”¼X)^2$$
Notice that the variance has *squared units*

In most cases it is more comfortable to work with the **standard deviation** $Ïƒ=\sqrt{ğ•X}.$

In that case the **population variance** can be written as $Ïƒ^2$

$$\text{Var}(ğ±)= \frac{1}{n}\sum_i (x_i-\bar x)^2=\sum_x (x-\bar x)^2\, p(x)$$


## Simple formula for population variance
We can rewrite the **variance of the population** with a simpler formula:
$$ğ•X=ğ”¼(X-ğ”¼X)^2=ğ”¼(X^2)-(ğ”¼X)^2$$
because
$$ğ”¼(X-ğ”¼X)^2=ğ”¼(X^2-2â‹…Xâ‹…ğ”¼X+(ğ”¼X)^2)\\
=ğ”¼(X^2)-2â‹…ğ”¼(Xâ‹…ğ”¼X)+ğ”¼(ğ”¼X)^2$$
but $ğ”¼X$ is a non-random number, so $ğ”¼(Xğ”¼X)=(ğ”¼X)^2$ and $ğ”¼(ğ”¼X)^2=(ğ”¼X)^2$

## Variance is almost linear
if $X$ and $Y$ are two **independent** random variables, and $Î±$ is a real number, then

+ $ğ•(X + Y)=ğ• X + ğ• Y$
+ $ğ•(Î± X)=Î±^2 ğ• X$

To prove the first equation we use that $ğ”¼(XY)=ğ”¼X\,ğ”¼Y,$ which is true when $XâŸ‚Y$

## Example: variance of coins
Let $X$ be a random variable corresponding to "success" or "failure", that we will represent by 1 and 0. The probability of success is $p$, and the probability of failure is $q.$

The variance of $X$ is
$$ğ•(X) = \sum_{xâˆˆ\{0,1\}} (x - p)^2â„™(X=x) = (1-p)^2â‹…p + (0-p)^2â‹…q = p q^2+p^2q = p q (p+q)=p q$$

It is easier to calculate using the simple formula
$$ğ•(X)=ğ”¼(X^2)-(ğ”¼X)^2 = p -p^2 =p(1-p)=p q$$

Now consider $n$ independent coins, all with the same probability of success, and we want to know how many of them are successful. Let
$$Y_n =\sum_{k=0}^n X_i$$
Then
$$ğ•(Y_n) = ğ•\left(\sum_{k=1}^n X_i\right)=\sum_{k=1}^n ğ•(X_i)=\sum_{k=1}^n p q = n p q$$

# Why we care about variance
The main reason is that it tells us how close is most of the population to the mean
$$â„™((X-ğ”¼X)^2â‰¥Î±) â‰¤ ğ•X/Î±$$
This is **Chebyshev's inequality** and it is always valid, for any probability distribution

It may be easier to understand if we call $Î±=c^2â‹…ğ•X.$ Then we have
$$â„™(|X-ğ”¼X| â‰¥ c\sqrt{ğ•X})â‰¤ 1/c^2$$
$$â„™(|X-ğ”¼X| â‰¤ c\sqrt{ğ•X})â‰¥ 1-1/c^2$$

$$â„™(-c\sqrt{ğ•X} â‰¤ X-ğ”¼X â‰¤ c\sqrt{ğ•X})â‰¥ 1-1/c^2$$
$$â„™(ğ”¼X-c\sqrt{ğ•X} â‰¤ X â‰¤ ğ”¼X+c\sqrt{ğ•X})â‰¥ 1-1/c^2$$


# Proof of Chebyshev's inequality
By the definition we have
$$ğ•(X)=ğ”¼(X-ğ”¼X)^2=\sum_x (x-ğ”¼X)^2â„™(X=x)$$
If we multiply the probability by a number that is sometimes 0 and sometimes 1, the sum has to be smaller. We multiply by $ã€š(x-ğ”¼X)^2â‰¥Î±ã€›$
$$ğ•(X)â‰¥ \sum_x (x-ğ”¼X)^2â„™(X=x)ã€š(x-ğ”¼X)^2â‰¥Î±ã€›$$
In that case, all $(X-ğ”¼X)^2â‰¥Î±$, therefore
$$ğ•(X)â‰¥ Î± \sum_x â„™(X=x)ã€š(x-ğ”¼X)^2â‰¥Î±ã€›=Î±â„™\left((X-ğ”¼X)^2â‰¥Î±\right)$$
Then we can divide by $Î±$ and we get our result

# Exercise
+ Given mean and variance, find a bound for the probability of the next experiment

# In summary
+ When experiments produce numbers we can calculate average and variance
+ The population has a fixed mean and variance, even if we do not know their values

-------

# Why probabilities? What can we use them for?
+ Probability of ğ‘¥ is the proportion of ğ‘¥ in the population
+ how many blonds/left-handed people are in Turkey?
+ How many obese people are in your city?

Since $â„™(X=x)=ğ”¼ã€šX=xã€›$ and $ğ”¼ã€šX=xã€›$ is the average, then calculating averages tells us about probabilities.

