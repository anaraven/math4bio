---
title: "Rules of Probabilities"
date: "2021-02-13 17:10"
lang: en
featured: false
mathjax: true
links:
  - "[[_drafts/2021/math4bio/experiments-outcomes-events]]"
  - "[[_drafts/2021/math4bio/how-to-write-about-probabilities]]"
  - "[[_drafts/2021/math4bio/multiplication-rule]]"
  - "[[_drafts/2020/Probabilities/Probabilities]] (raw notes)"
  - "[[_drafts/2020/Probabilities/2-logic]]"
  - "[[_drafts/2020/Probabilities/3-probabilities]]"
  - "[[_drafts/2020/Probabilities/3-probability]]"
  - "[[_drafts/2020/Probabilities/3.1-events]]"
  - "[[_drafts/2020/Probabilities/3.2-bracket-notation]]"
  - "[[_drafts/2020/Probabilities/4-distributions]]"
  - "[[_drafts/2020/Probabilities/4-expected]]"
  - "[[_drafts/2020/Probabilities/4.1-sample-vs-population]]"
  - "[[_drafts/2020/Probabilities/5-LLN-CLT]]"
  - "[Channel MindYourDecisions](https://youtu.be/Bt5uwmOa_pc)"
---

# NaÃ¯ve probabilities
Most readers will already be familiar with the idea that probabilities are "number of positive cases" divided by "number of total cases". This is a useful first approach, but it is easy to get confused. For example, if you throw a dice, what is the probability of getting a 6? 

It may be tempting to think that there are two possible outcomes: either you get a 6 or you do not. Only one of these outcomes is positive, so you we may be tempted to say that the probability is 50%. But the same reasoning can be used to conclude that the probability of getting a 5 is 50%, and the probability of getting a 4, or getting a 3, a 2 or a 1.

If that reasoning was correct, all possible outcomes would have probability 50%. But then we would have a total probability of 300%.

We have to be careful.

If you do not see the error of this reasoning, I will bet you one dollar for each dice cast.

# Rules of probabilities
Here are the basic rules that will allow us to assign probabilities.

## The probability of any event is a number between 0 and 1
Most readers will already be familiar with the idea that probabilities are "number of positive cases" divided by "number of total cases".    $$0â‰¤â„™(A|Z)â‰¤1$$

<!-- Venn diagram. A circle in a square -->
![Probability as areas, but the drawing boards depends on the context.](../../../images/msr/venn3.png)


A canvas ğ›€ represents the target for a dart. We know that the dart is going to fall _somewhere_ inside the region ğ‘, never outside.
All points in the canvas have the same chance of being hit by the dart. The event ğ´ is a region in the of being hit by the dart. The probability is the area of ğ´ respect to the area of ğ‘.

If we do not have any extra information, at least we know Î©. In other words ğ‘=Î©.

## If we are sure that something will happen, its probability is 1
If we know that an event $A$ is true then its probability is 1. Or, in short,
    $$â„™(\text{True})=1$$

To be more precise, remember that this probability depends our current knowledge (ğ‘) about this experiment. If the symbol ğ‘ represent all we know  about this experiment, and this knowledge implies that ğ´ must be true (ğ‘ âŸ¹ ğ´), then $â„™(ğ´|ğ‘)=1.$

Graphically, this is represented by an area ğ‘ that is contained inside a circle ğ´. Sometimes ğ‘ is equal to ğ´, sometimes ğ‘ is a subset of ğ´.

## If we are sure that something will not happen, its probability is 0
If $A$ is false (given the context $Z$), then its probability is 0
$$\text{If }Z âŸ¹ (\text{not }A)\text{, then }â„™(A|Z)=0$$
or, in short, the probability of a False event is zero
$$â„™(\text{False})=0$$

## when one event is more probable, the opposite event is less probable
More in general, when one event is more probable, the opposite event is less probable by the same measure
    $$â„™(A|Z)=1-â„™(\text{not }A|Z)$$
    or, in other words
    $$â„™(A|Z)+â„™(\text{not }A|Z)=1$$

Venn diagram of ğ‘ split in two parts.

## Partition of Î©
Generalization of the previous idea. Let's split Î© in ğ‘› parts. We may call them $A_1,A_2,â€¦,A_n$. They do not need to have equal size. Each outcome ğ‘¥ in Î© is in one and only one event $A_i$.
Then
$$â„™(A_1)+â„™(A_2)+ â‹¯ + â„™(A_n) =1$$


In other words, they must fulfill two conditions:
If $A_1,â€¦,A_n$ are ğ‘› events such that
$$Î©=A_1 âˆª A_2 âˆª â€¦ âˆª A_n$$
and whenever ğ‘– â‰  ğ‘— we have
$$A_i âˆ© A_j= âˆ…$$

+ The previous rule is a particular case of this rule. Therefore this rule is a generalization of the previous one
+ It can be proved formally

5. If two events â€”$A_1$ and $A_2$â€” are incompatible â€”that is, they cannot be both true at the same timeâ€” then
$$â„™(A_1 \text{ or }A_2|Z)=â„™(A_1|Z)+â„™(A_2|Z)$$

6. If two events â€”$A_1$ and $A_2$â€”  can be both true at the same time then
$$â„™(A_1 \text{ or }A_2|Z)=â„™(A_1|Z)+â„™(A_2|Z)-â„™(A_1 \text{ and }A_2|Z)$$

Do not count the intersection twice. We will show a more rigorous proof later.

## Indifference principle


# Exercises

